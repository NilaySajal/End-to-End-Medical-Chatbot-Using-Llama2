{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /Users/nilaypatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from pypdf) (4.11.0)\n",
      "Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nilaypatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "api_env = os.getenv('PINECONE_API_ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf('/Users/nilaypatel/End-to-End-Medical-Chatbot-Using-Llama2/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637\n"
     ]
    }
   ],
   "source": [
    "print(len(extracted_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings():\n",
    "    vector_embeddings = []\n",
    "    for i in range(len(text_chunks)):\n",
    "        vector_embeddings.append(embeddings.embed_query(text_chunks[i].page_content))\n",
    "    return vector_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pc = Pinecone(api_key = api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index('mchatbot')\n",
    "v = generate_embeddings()\n",
    "vectors = []\n",
    "ids = []\n",
    "for i in range(len(v)):\n",
    "    ids.append('vec'+str(i+1))\n",
    "for i in range(len(v)):\n",
    "    vectors.append({'id':ids[i],'values':v[i]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0017460581148043275, -0.03350289911031723, -0.03290392458438873, 0.007168038282543421, -0.01460327859967947, 0.010261868126690388, -0.011515314690768719, 0.22930210828781128, -0.023232391104102135, 0.004120429512113333, -0.036560941487550735, 0.08592110127210617, 0.012972128577530384, 0.05221787095069885, -0.1023261770606041, -0.0031389270443469286, -0.012686857022345066, 0.00047185903531499207, -0.028485851362347603, -0.05025915428996086, 0.01155101228505373, 0.07780641317367554, 0.09282822906970978, -0.013797281309962273, -0.016935022547841072, -0.025955891236662865, -0.0495651438832283, -0.04613136872649193, 0.0072905379347503185, -0.01355320867151022, 0.03843952342867851, 0.06280476599931717, 0.018353847786784172, 0.008242879062891006, 0.001715547521598637, -0.03986182063817978, -0.011638627387583256, 0.016446225345134735, 0.025595564395189285, 0.09104611724615097, 0.029672672972083092, -0.05416030064225197, -0.045765653252601624, -0.013853880576789379, 0.025773564353585243, 0.01032308116555214, -0.053630974143743515, 0.021221522241830826, 0.017027704045176506, 0.1161222755908966, -0.06963177025318146, -0.09572754055261612, -0.03983989730477333, 0.05236920341849327, 0.0252602007240057, -0.03127450868487358, -0.07005149871110916, -0.05956612154841423, -0.09544864296913147, -0.054121289402246475, -0.00021302595268934965, 0.00025521902716718614, 0.012184767052531242, 0.036847200244665146, -0.09168800711631775, -0.016031546518206596, 0.056772515177726746, -0.06110306829214096, 0.05796804279088974, -0.036524537950754166, -0.021421393379569054, -0.04721979424357414, 0.03454087674617767, 0.12064339220523834, -0.013788485899567604, -0.06848539412021637, 0.012004920281469822, -0.05972893536090851, -0.05643807351589203, -0.10106115788221359, 0.05889035761356354, -0.020776810124516487, 0.09746566414833069, 0.07813999056816101, -0.035233233124017715, -0.014866293407976627, 0.040357086807489395, 0.07460878044366837, -0.013026466593146324, -0.028441667556762695, 0.10370929539203644, 0.019506335258483887, 0.029694216325879097, 0.007636211346834898, 0.0056925443932414055, -0.0007858830504119396, -0.04315328970551491, 0.007750414777547121, -0.017907142639160156, 0.06111788749694824, -0.025316860526800156, -0.10494086891412735, -0.05342495068907738, 0.009893708862364292, 0.014465460553765297, -0.06589166074991226, 0.009222935885190964, -0.13625682890415192, 0.021162550896406174, -0.01161877065896988, 0.03450930118560791, 0.0604950450360775, 0.01565295271575451, -0.012806546874344349, -0.007194920908659697, 0.055682472884655, 0.07992610335350037, 0.05983535200357437, 0.09587424248456955, 0.01820429600775242, 0.02359643206000328, -0.08910961449146271, -0.007128911092877388, -0.09076812118291855, 0.04723312705755234, 0.0041341157630085945, 0.003397879656404257, -2.0226564153996094e-33, 0.015145715326070786, -0.004016455728560686, 0.04603564739227295, 0.06628161668777466, 0.08750344067811966, 0.03237524256110191, -0.013098559342324734, -0.06530214846134186, 0.07942299544811249, -0.1063862293958664, -0.07034214586019516, 0.03889160603284836, 0.01438814401626587, 0.054484810680150986, -0.10632545500993729, 0.0015778971137478948, -0.07627755403518677, 0.029418019577860832, -0.0202549509704113, -0.010341105051338673, 0.00771615793928504, 0.015365838073194027, -0.030866391956806183, 0.03806666284799576, -0.0846736803650856, 0.06119650602340698, -0.006315986160188913, 0.021086081862449646, 0.09480433911085129, -0.028975773602724075, -0.024698695167899132, -0.02624206617474556, 0.010229132138192654, -0.04816935211420059, -0.050850801169872284, 0.06431730836629868, -0.06250055879354477, -0.01794431172311306, -0.0032577519305050373, -0.002178005175665021, 0.004050987306982279, 0.05613984540104866, 0.021659541875123978, -0.028459057211875916, 0.06688952445983887, -0.018423568457365036, -0.1386348158121109, -6.53480674372986e-05, 0.09188712388277054, -0.057828906923532486, 0.05180114135146141, -0.03339908644556999, 0.06356910616159439, -0.03353029489517212, 0.0035603151191025972, 0.05478646978735924, -0.059278253465890884, 0.02796686813235283, 0.019815074279904366, 0.030648209154605865, 0.0945383757352829, 0.07339680939912796, 0.02208285592496395, -0.034395355731248856, -0.008398774079978466, 0.016077406704425812, -0.10198624432086945, -0.1076703816652298, -0.04845404252409935, -0.046985894441604614, -0.12305164337158203, 0.01794607937335968, 0.02716819941997528, 0.041503097862005234, -0.012137949466705322, 0.016134953126311302, 0.007807489950209856, -0.030696380883455276, -0.0369555838406086, -0.07249002158641815, -0.0659404993057251, -0.05230473354458809, 0.022644761949777603, 0.10688148438930511, -0.0343763567507267, -0.007190043106675148, 0.004040638916194439, -0.012765740044414997, -0.0357331782579422, -0.00952134933322668, -0.0376090444624424, 0.025724735110998154, -0.07330160588026047, 0.01839981973171234, -0.01315235160291195, -2.43915739011197e-33, -0.03649843484163284, -0.0389849878847599, -0.024660833179950714, 0.05277736485004425, 0.05715387314558029, 0.08485238254070282, -0.04777827858924866, 0.04885168373584747, 0.0936603844165802, 0.02445533126592636, 0.10703858733177185, -0.0448780283331871, 0.013439498841762543, 0.010380106046795845, -0.032158415764570236, 0.037564631551504135, -0.02451690286397934, -0.015364415943622589, -0.08388064056634903, 0.07285159826278687, -0.08349569141864777, 0.053134381771087646, -0.05021432787179947, 0.02177390456199646, 0.09023480117321014, 0.014781389385461807, 0.0397091843187809, -0.017786024138331413, -0.01812116988003254, -0.057365160435438156, -0.014359092339873314, -0.019216595217585564, -0.07116210460662842, -0.03887922689318657, -0.06919411569833755, 0.015993360430002213, 0.03935175761580467, -0.06669551879167557, -0.027239752933382988, -0.04119197279214859, 0.08880133926868439, -0.03152485564351082, 0.02098911441862583, 0.007525244727730751, 0.006864247843623161, -0.00016021434566937387, -0.03395671024918556, -0.019771624356508255, -0.01390139851719141, -0.02347424440085888, 0.05024155601859093, 0.004815859254449606, 0.003084113821387291, 0.013711358420550823, 0.04268842190504074, -0.01031945738941431, -0.015616221353411674, -0.13140307366847992, 0.03932565823197365, 0.003462089691311121, 0.004625445231795311, -0.02217300795018673, -0.0799821987748146, 0.07068225741386414, 0.01325169950723648, 0.013216596096754074, -0.031048603355884552, 0.016299361363053322, 0.07485274225473404, -0.020337792113423347, -0.03757906332612038, 0.0027204519137740135, -0.07825031131505966, -0.07273509353399277, -0.0015074977418407798, -0.0015040482394397259, -0.0480678416788578, -0.022696973755955696, 0.0023470427840948105, -0.10254427790641785, -0.010626746341586113, -0.05898872762918472, -0.02825745940208435, 0.018367942422628403, -0.024334125220775604, 0.006143596488982439, 0.05812554806470871, 0.006210016086697578, -0.0041254740208387375, 0.004883240442723036, -0.051727525889873505, -0.0026522877160459757, -0.08568169176578522, 0.041441164910793304, -0.007155630271881819, -2.368167706379154e-08, 0.056130871176719666, -0.014770290814340115, -0.0016939738998189569, -0.0011319196783006191, -0.004112991038709879, -0.07847736775875092, -0.03272828832268715, 0.08840589225292206, -0.009142749011516571, 0.08083555847406387, -0.0682123526930809, 0.08852607011795044, 0.0188254676759243, -0.004044069908559322, 0.019472334533929825, 0.05469337850809097, -0.004570755176246166, 0.05013274773955345, -0.020886126905679703, -0.004381033591926098, 0.012420032173395157, -0.04024988040328026, -0.017629554495215416, -0.07264229655265808, 0.027827171608805656, 0.026226604357361794, 0.009220127947628498, 0.025732293725013733, -0.009361174888908863, -0.09865126013755798, -0.03130585700273514, 0.051363393664360046, 0.011322773061692715, -0.04961381480097771, -0.047163646668195724, -0.005473940633237362, 0.06890671700239182, -0.04070519655942917, 0.054232992231845856, -0.019241902977228165, 0.014344986528158188, -0.044434837996959686, -0.0256748516112566, 0.0313546285033226, 0.06115221604704857, -0.02683873474597931, 0.049135178327560425, 0.056448329240083694, 0.027938080951571465, -0.08463852107524872, -0.0056616030633449554, 0.007060903124511242, 0.10265115648508072, -0.019236577674746513, -0.0814581960439682, 0.0712505578994751, 0.018038352951407433, -0.01757209561765194, -0.0004301401786506176, -0.1040591448545456, 0.0028414856642484665, -0.005556431133300066, 0.10660902410745621, 0.050997186452150345]\n"
     ]
    }
   ],
   "source": [
    "print(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "for i in range(len(vectors)):\n",
    "    vctrs = vectors[i:i+batch_size]\n",
    "    index.upsert(vctrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in /Users/nilaypatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (3.2.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/nilaypatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from pinecone-client) (2024.2.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/nilaypatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from pinecone-client) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/nilaypatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from pinecone-client) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/nilaypatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from pinecone-client) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=CTransformers(model=\"/Users/nilaypatel/End-to-End-Medical-Chatbot-Using-Llama2/model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docsearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m qa\u001b[38;5;241m=\u001b[39mRetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[1;32m      2\u001b[0m     llm\u001b[38;5;241m=\u001b[39mlm, \n\u001b[1;32m      3\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m----> 4\u001b[0m     retriever\u001b[38;5;241m=\u001b[39m\u001b[43mdocsearch\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}),\n\u001b[1;32m      5\u001b[0m     return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      6\u001b[0m     chain_type_kwargs\u001b[38;5;241m=\u001b[39mchain_type_kwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docsearch' is not defined"
     ]
    }
   ],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=lm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
